---
title: "Complex Data Pipelines"
subtitle: ""
format: 
  revealjs:
    footer: "[USCOTS Intermediate R Workshop](https://atheobold.github.io/uscots-intermediate-r/)"
    theme: [simple, styles.scss]
    embed-resources: true
    code-fold: true
    auto-stretch: true
editor: source
execute:
  echo: true
---

```{r}
#| include: false
library(tidyverse)
library(countdown)
dat_ff <- read_csv(here::here("materials", "data", "fastfood.csv"))
```


# Asking more complex research questions



## Background: Intro level RQs

* The **Big Five** tidyverse verbs:

    + `arrange`
    + `filter`
    + `mutate`
    + `group_by`
    + `summarize`
    
* (Doesn't have to be tidyverse syntax!)

## Dataset 1: Fast food nutrition

```{r}
dat_ff
```

## Single-function RQs

Type of basic questions:

* `arrange` What item has **the most** calories?

* `mutate` **Calculate** the saturated fat to total fat ratio of each item.

* `summarize` What is the **median** calorie item?

* `filter` **How many** items have more than 1000 calories?

* `group_by` Same questions, but **within each** restaurant.

## Intro pipeline RQs

* `mutate` -> `arrange` "What item has the highest saturated fat to total fat ratio?"

* `mutate` -> `filter` "How many items have more than 50% of total fat in saturated form?"

* `group_by` -> `summarize` -> `filter` "How many restaurants have at least one 2000 calorie item?"

* any -> plot: "Make a boxplot of average saturated fat percentages for items in each restaurant."


## YOUR TURN

::: {.r-fit-text}
Choose one of your clean tabular datasets.

Jot down some research questions or tasks that are answerable with intro-level pipelines on that dataset.
:::

```{r}
#| echo: false
countdown(minutes = 3)
```

### Ryan's choice: 

Find the highest protein to calories ratio item: 

```{r}
r_ff = readr::read_csv("data/fastfood.csv")
r_ff |> 
  mutate(
    pro_cal = protein / calories, 
    max_pro_cal = max(pro_cal, na.rm = TRUE)
  ) |>
  arrange(desc(pro_cal)) |>
  filter(max_pro_cal == pro_cal)
```


```{r}
# NBA read-in
```





# Designing problems for complex pipelines

## Making it complex

Ways to level up **pipeline complexity** of the RQs:

1. Changing the *cases/rows* (esp for *visualization*)

2. Operations *inside* `mutate` or with `group_by`

3. Many pivots, especially for *summary tables*

4. Multiple datasets and *joins*


## Change the cases/rows

* Summarizing by group: rows become *restaurants* not *items*.

```{r}
dat_ff |>
  group_by(restaurant) |>
  summarize(mean(calories))
```

## Change the cases/rows

* Pivoting: rows become *nutrition measurement for an item* rather than *items*.

```{r}
dat_ff |>
  pivot_longer(calories:calcium,
               values_to = "amount",
               names_to = "nutritional_item")
```

## Change the cases/rows

* Distinct: rows become *restaurants* rather than *items*.

```{r}
dat_ff |>
  distinct(restaurant, .keep_all = TRUE)
```

```{r}
#| include: false
#| eval: false

## old idea, might use later

flagships <- c("Mcdonalds" = "Big Mac", 
               "Burger King" = "WHOPPER w/ Cheese", 
               "Taco Bell" = "Crunchwrap Supreme®",
               "Chick Fil-A" = "Chicken Sandwich", 
               "Subway" = "Footlong Subway Club",
               "Arbys" = "Classic Roast Beef",
               "Dairy Queen" = "DQ Ultimate® Burger",
               "Sonic" = "Sonic Bacon Cheeseburger (w/mayo)")

dat_ff |>
  filter(item %in% flagships)

dat_ff |>
  group_by(restaurant) |>
  mutate(
    flagship_calories = .data |> filter(item %in% flagships) |> pull(calories)
  )
```




## Do more with mutate

##  `group_by` |> `mutate`

**What is the highest-calorie single item at each restaurant?**

```{r}
dat_ff |>
  group_by(restaurant) |>
  mutate(
    max_calories = max(calories),
    prop_of_max_cal = calories/max_calories
  ) 
```

## YOUR TURN


::: {.r-fit-text}
Think of a measurement *by category* that you might want to add to *every additional row* of your dataset, for purposes of comparing.
:::

```{r}

#| echo: false
countdown(minutes = 3)
```

### Ryan

Find the highest protein to calories ratio item by restaurant:

```{r}
r_ff = r_ff |> 
  group_by(restaurant) |>
  mutate(
    pro_cal = protein / calories, 
    max_pro_cal = max(pro_cal, na.rm = TRUE)
  )
```

## String parsing

**Find the median calories for a burger at each restaurant.**

```{r}
dat_ff |>
  mutate(
    is_burger = str_detect(item, "burger")
  ) |>
  filter(is_burger) |>
  group_by(restaurant) |>
  summarize(median(calories))
```

## Regular expressions

*Optional:* Level up this task with regular expressions!

**Find the median calories for a CHEESE burger at each restaurant.**

```{r}
dat_ff |>
  mutate(
    is_cheese_burger = str_detect(item, "[Ch]ee(z|se) ?[bB]urger")
  ) |>
  filter(is_cheese_burger) |>
  group_by(restaurant) |>
  summarize(median(calories))
```

## YOUR TURN

::: {.r-fit-text}
Find a string column in your dataset, jot down 1-3 new *non-string* columns you might want to make by parsing that string.
:::

```{r}
#| echo: false
countdown(minutes = 3)
```

### Ryan 

From `item`, do the following: 

1. Create a new column called `is_salad`. 
2. Create a new column called `has_chicken` (note: nuggets, chicken, ...).

```{r}
# r_ff |> 
#   mutate()

```



## Complex/unvectorized functions and mapping

**For each item, give the amount of saturated fat or of trans fat, whichever is larger**

```{r}
## This won't work!

dat_ff |>
  mutate(
    bad_fat = max(sat_fat, trans_fat)
  )

## Ryan: this does!
dat_ff |>
  rowwise() |> 
  mutate(
    bad_fat = max(sat_fat, trans_fat)
  )
```


## Complex/unvectorized functions and mapping

**For each item, give the amount of saturated fat or of trans fat, whichever is larger**

```{r}
## This will!

dat_ff |>
  mutate(
    bad_fat = pmap_dbl(list(sat_fat, trans_fat), max)
  )
```



## YOUR TURN - Try an activity

::: {.r-fit-text}
> Your city has just passed a law that fast food items need to contain a warning note if they have over 40% calories from fat, over 40% saturated fat, or any trans fats at all.

> Write a function that creates a warning note based on an items nutritional information.

> Then, use that function inside of `mutate` to add a warning label for each item.

As you work on this, make note of any pain points, confusions, or complexities that differentiate this task from an "Intro level" one.
:::

```{r}
#| echo: false
countdown(minutes = 10)
```


```{r}
# r_ff |> 
  
```



## Answer

```{r}
check_healthy_fat <- function(calories, cal_fat, total_fat, sat_fat, trans_fat) {
  
  cal_fat_pct <- cal_fat/calories
  sat_fat_pct <- sat_fat/total_fat
  
  warning <- ""
  
  if (!is.na(cal_fat_pct) & cal_fat_pct > 0.4) {
    warning <- paste(warning, "Calories from fat is high.")
  }
  
  if (!is.na(sat_fat_pct) & sat_fat_pct > 0.4) {
    warning <- paste(warning, "High saturated fat percent.")
  }
  
  if (!is.na(trans_fat) & trans_fat > 0) {
    warning <- paste(warning, "Contains trans fat.")
  }
  
  return(warning)
  
}
```

## Answer


```{r}
dat_ff |>
  mutate(
    healthy_fat_warning = pmap_chr(list(calories, cal_fat, total_fat, sat_fat, trans_fat), check_healthy_fat)
  )
```


## Non one-to-one Joins

Consider this additional dataset:

```{r}
#| echo: false
dat_loc <- read_csv(here::here("materials", "data", "Fast_Food_Restaurants_US.csv"))
```

```{r}
dat_loc
```

## Complex joins

There are some complications in joining this data to our nutritional data...

* The restaurants aren't named consistently, e.g. "Sonic" vs "SONIC Drive-In".

* Sometimes there are multiple matches - "Dairy Queen", "Wolf's Dairy Queen", "Dairy Heaven", "Dairy Queen (Treat Only)"

* Many restaurants appear in `dat_loc` but not `dat_ff`.

* Each restaurant appears multiple times in both `dat_loc` and `dat_ff`.

## Filtering Joins

`anti_join` can be used to check which keys don't match:

```{r}
dat_ff |>
  anti_join(dat_loc,
            by = c("restaurant" = "name")) |>
  distinct(restaurant)
```


## Mutating Joins

"Where can I get a burger?"

```{r}
dat_ff |>
  filter(str_detect(item, "burger")) |>
  distinct(restaurant) |>
  left_join(dat_loc,
            by = c("restaurant" = "name"))
```

## Mutating Joins

Notice:

* We used `distinct` on `dat_ff` first.  This makes it a *one-to-many* join instead of a *many-to-many*.  Why is this good/what if we didn't?

* `dat_ff` had 515 rows. `dat_loc` had 10000.  The result of our pipeline has `1075`. *When a join is not one-to-one, you can't predict the number of rows easily!*

* What if we had used `full_join`?  `right_join`?


## YOUR TURN

::: {.r-fit-text}
Look at your collection of data - where are there keys to match?  Are any of them not one-to-one, or otherwise complex?
:::

```{r}
#| echo: false
countdown(minutes = 3)
```


## Multiple Pivots

A common pipeline with multiple pivots might be:

1. Do a calculation
2. Pivot longer
3. Join
4. Calculate some summary by groups
5. Pivot back wider

## Example

> What city has the most burgers?

```{r}
burger_counts <- dat_ff |> 
  mutate(
    is_burger = str_detect(item, "burger")
  ) |>
  group_by(restaurant) |> 
  count(is_burger) |>
  pivot_wider(names_from = is_burger,
              values_from = n,
              names_prefix = "burger_")

burger_counts
```

## Example

> What city has the most burgers?

```{r}
burger_counts |>
  left_join(dat_loc,
            by = c("restaurant" = "name")) |>
  group_by(city) |>
  summarize(
    total_burgers = sum(burger_TRUE, na.rm = TRUE)
  ) |>
  arrange(desc(total_burgers))
```




## YOUR TURN

::: {.r-fit-text}
Sketch a summary table that might be interesting for your data, then reverse engineer the pivots and joins needed to achieve it.
:::


```{r}
#| echo: false
countdown(minutes = 5)
```

<!-- # Teaching unit testing principles -->

<!-- ## "Checking in" on the pipeline -->

<!-- ## Look at the extremes -->

<!-- ## Try to break it -->

<!-- # Summary and resources -->

<!-- ## RegEx -->

<!-- ## Map/apply inside and outside -->

<!-- ## Custom functions for pipeline problems -->

<!-- ## List-cols -->


# Designing pipeline activities

## "Transition" or "Scaffold" activities

Some suggested "scaffold" activities:

1. Sketch a plan

2. Reorder a pipeline

3. Fill in a blank

## Sketch a plan

* Begin with **pen-and-paper only** - no computer, no code

* Plan out the steps needed to address the RQ

* Include "sketches" of the how the dataset should look after each step

## Reorder a pipeline

Provide all the pipeline elements, ask students to put them in proper order.

```
burger_counts |>

a) summarize(
    total_burgers = sum(burger_TRUE, na.rm = TRUE)
  )
b) group_by(city)
c) left_join(dat_loc,
            by = c("restaurant" = "name"))
d) arrange(desc(total_burgers))
  
```

Answer: `c-b-a-d`

## Fill in a blank

This could mean fill in a blank in **code** to achieve a goal ...

```
burger_counts |>
  left_join(dat_loc,
            by = c("restaurant" = "name")) |>
  ___________ |>
  summarize(
    total_burgers = sum(burger_TRUE, na.rm = TRUE)
  ) |>
  arrange(desc(total_burgers))

```

## Fill in a blank

This could also mean fill in an *intermediate dataset step*:

```
[Original Data Sketch]
->
[Joined Data Sketch]
->
STUDENTS FILL IN THIS SKETCH
->
[Final output]
```


## YOUR TURN

::: {.r-fit-text}
For your dataset, come up with some research questions that require a complicated pipeline to address. 

Sketch out the steps needed to answer a research question.

Jot down some ideas about how you would make *transitional* student questions out of these - e.g., which steps would you show and which would you leave blank?
:::

```{r}
#| echo: false
countdown(minutes = 10)
```

